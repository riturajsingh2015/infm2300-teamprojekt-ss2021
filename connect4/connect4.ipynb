{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Gewinnt\n",
    "Dieses Notebook beschäftigt sich dem Spiel `Connect 4`, welches im deutschen Sprachraum auch als `4 Gewinnt` bekannt ist. Ziel des Spiels ist es 4 Steine seiner eigenen Farbe in horizontaler, vertikaler oder diagonaler Richtung in einem Spielbrett zu Platzieren.\n",
    "![4 Gewinnt](Logo.jpg \"Title\")\n",
    "\n",
    "## Datensatz\n",
    "Zu diesem Spiel wurde ein umfangreicher Datensatz erhoben. Der Zustand eines Spiels wurde festgehalten, während beide Spieler je 4 Steine platziert hatten. Zu dieser gespielten Partie wurde dann das Endergebnis aus Sicht des ersten Spielers, also Sieg, Niederlage bzw. Unentschieden vermerkt.\n",
    "\n",
    "Quelle des Datzensatzen:\n",
    "http://archive.ics.uci.edu/ml/datasets/Connect-4\n",
    "\n",
    "### Eigenschaften und Aufbau\n",
    "Das Spielbrett ist aufgebaut als Gitter und ist folgendermaßen unterteilt:\n",
    "- **7 Felder horizontal**, beschriftet von **a bis g**\n",
    "- **6 Felder vertikal**, beschriftet von **1 bis 6**\n",
    "Das ergibt insgesamt 42 mögliche Steinpositionen. Zusammen mit Endergebnis enthält der Datensatz `43 Attribute`. Spieler Eins wird als **x** und Spieler 2 als **o** gekennzeichnet. **b** bedeutet das dort kein Stein liegt.\n",
    "\n",
    "Der Datensatz ist wie folgt aufgebaut:\n",
    "\n",
    "- 1. a1: {x,o,b} (x = Stein Spieler 1, o = Stein Spieler 2, b = Leeres Feld)\n",
    "- 2. a2: {x,o,b}\n",
    "- 3. a3: {x,o,b}\n",
    "- 4. a4: {x,o,b}\n",
    "- 5. ...\n",
    "- 41. g5: {x,o,b}\n",
    "- 42. g6: {x,o,b}\n",
    "- 43. Class: {win,loss,draw} (Sieg Spieler 1, Niederlage Spieler 1, Unentschieden)\n",
    "\n",
    "Der Datensatz beinhaltet insgesamt **67557** Einträge\n",
    "\n",
    "## Zielstellung\n",
    "Mit Hilfe von Maschine Learning Verfahren soll eine Möglichkeit geschaffen werden, den Ausgang des Spiel in dem 9. Zug vorhersagen zu können.\n",
    "Da das Ziel aus 3 konkreten, voneinander getrennten Zuständen besteht, spricht man hier auch von einer Klassifikationsaufgabe.\n",
    "\n",
    "***\n",
    "\n",
    "## Lösungansätze\n",
    "Wie so oft gibt es für ein Problem nicht nur eine Lösungsmöglichkeit. Obwohl häufig neuronale Netzwerke als überwachtes Lernverfahren der künstlichen Intelligenz bei Vorhersageproblemen verwendet werden, wird im Folgenden auch noch eine zweite Variante vorgestellt.\n",
    "\n",
    "\n",
    "### Lösungsansatz I: Neural Network\n",
    "Als ersten Ansatz wurde ein `Deep Learning`-Netzwerk eingesetzt. Die konkrete Ausprägung des Netzwerks basiert auf Erfahrungen aus Experimenten und der Weg zur abschließenden Lösung wird im Notebook erläutert. Für den Einsatz eines solchen Netzwerks wurden folgende Merkmale als entscheidend betrachtet.\n",
    "\n",
    "<u>Vorteile:</u>\n",
    " - neuronale Netze sind hoch anpassbar an jede Art von Klassifikationsproblemen\n",
    " - Solche Netze bzw. deren Eingaben können effizient parallelisiert werden. Daher ist es auch schon mit TensorFlow möglich die GPU zu nutzen um die Trainings auszuführen\n",
    " \n",
    "<u>Nachteile:</u>\n",
    " - Es ist viel Training und experiementieren bzw. Erfahrung notwendig um eine akzeptable Lösung zu finden \n",
    " - Oft ist es schwer zu visualisieren/interpretieren wie Daten zusammenhängen oder vorher der Wissenserwerb des Netzwerks kommt\n",
    " \n",
    "### Lösungsansatz II: Neural Network - Raster\n",
    "Bei der Betrachtung des Ausgangsproblems kann man dieses auch als Raster betrachten. Das Spielfeld ist als Gitter aufgebaut, bei dem die Steinpositonen auf eine regelbasierte Weise zusammenhängen. Daher könnte eventuell auch ein Neuronales Netz eine Lösung liefern, dass eher für Rasterdaten verwendung findet wie es beispielsweise bei Bildern der Fall ist. \n",
    "\n",
    "### Lösungsansatz III: DecisionTrees\n",
    "Während der Bearbeitung mit Neuronalen Netzwerken schien eine weitere - die der `DecisionTrees` als vielversprechende Alternative. Mit Hilfe der Lektüre `Maschinelles Lernen` vom Autor `Jörg Frochte` wurden die Möglichkeiten der Klassifizierung mit Hilfe von Binärbäumen analysiert und angewendet. Konkret wird der `DecisionTreeClassifier` sowie der `RandomForestClassifier` - von scikit-learn eingesetzt, \n",
    "Die Entscheidung für den Einsatz der Verfahren ergibt sich aus folgenden Überlegungen.\n",
    "\n",
    "<u>Vorteile:</u>\n",
    " - Einfach zu verstehen und einzusetzen. Es wird kaum Vorarbeit benötigt\n",
    " - Im Gegensatz zu Neuronalen Netzen ist ein `DecisionTree`sehr schnell erstellt und einsatzbreit\n",
    " \n",
    "<u>Nachteile:</u>\n",
    " - Im Gegensatz zu Neuronalen Netzen bestehen nur begrenzte Möglichkeiten der Verbesserung beim konkreten Problemen. Kann ein Problem nicht akzeptabel gelöst werden, dann kann auch kaum eine Verbesserung mit Hilfe von Parametern erzielt werden.\n",
    "\n",
    "## Interpretation und Vergleich der Ergebnisse\n",
    "Alle Ergebnisse werden gesammelt und beim jeweiligen Lösungsansatz interpretiert. Abgeschlossen wird dies durch einen Vergleich der 3 vorgestellten Lösungsansätze.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorarbeiten\n",
    "Für Lösungsansätze wird eine Reihe von Third-Party-Bibliotheken verwendet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es kam zu Problemen mit der Tensoflow beim Lösungsansatz II bei Nutzung der Layer - Die genaue Ursache ist unbekannt, aber ein Downgrade zu 2.3.1 schaffte Abhilfe\n",
    "#%pip install -U tensorflow==2.3.1\n",
    "\n",
    "# Sollte dies wieder Erwarten nicht funktionieren dann auch die Abhängigkeiten mit downgraden\n",
    "#%pip install -U tensorflow==2.3.1 --use-feature=2020-resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import aller ThirdParty Bibliotheken \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Bibliothek `Pandas` bietet eine Reihe von praktischen Hilfsfunktionen für die Arbeit mit Neuronalen Netzen bzw. deren Datensätzen. Da es eventuell auf der zu Grunde liegenden Jupyter Notebook Installation nicht zur Verfügung steht, wird es bei Bedarf installiert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten des Connect-4 lassen sich einfach visualiseren. Für diese `Datenexploration` wurde eine eigene Klasse `Connect4` erstellt die diese Aufgabe übernimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from connect4 import Connect4\n",
    "connect4_obj=Connect4(\"connect-4.data\")\n",
    "dataframe=connect4_obj.get_dataframe()\n",
    "print(\"Der Datensatz besitzt folgende Dimensionen (Zeilen/Spalten)\", dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um sich ein Bild von dem Zustand des Spiels zu machen in der eine Vorhersage getroffen werden soll, kann nun jede einzelne Zeile des Datensatzes visualisert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect4_obj.visualize_row(row_number=8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Die Eingangsdaten müssen in numerische Werte umgewandelt, um mit diesen Rechnen zu können. Diese Umwandlung übernimmt ebenfalls die `Connect4` Bibliothek.\n",
    "\n",
    "Danach wird der Datensatz noch aufgeteilt in:\n",
    "- **Eingabevektoren** (Steinpositionen)\n",
    "- **Zielvektoren** (Spielausgang)\n",
    "\n",
    "Diese werden jeweils weiter aufteilt in:\n",
    "- **Trainingsdaten**\n",
    "- **Validierungsdaten**\n",
    "\n",
    "die dann zum Trainieren der Neuronalen Netzwerke benutzt werden bzw. um die Trainierten Netze zu überprüfen. Wichtig hierbei ist, dass die Auswahl zufällig erfolgt, um ein `einseitiges` Lernen des neuronalen Netzwerkes zu vermeiden. Auch sollte die Menge an Trainingsdaten gegenüber den Validierungsdaten eine Balance finden, so dass ein `auswendig` lernen vermieden wird, bzw. eine `Generalisierung` noch möglich ist. Eine Wahl um die 20% Valdierungsdaten ist üblicherweise ein guter Ausgangspunkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der Datensatz wurde bereits eingelesen und mit numerical_dataframe() kann eine numerische Repäsentation erzeugt werden.\n",
    "dataset = connect4_obj.numerical_dataframe()\n",
    "\n",
    "# Aufteilen in Eingabe- und Zielvektoren\n",
    "inputData = dataset[:,0:42]\n",
    "targetData = dataset[:,42]\n",
    "\n",
    "# Erzeugen von Traings- und Validierungsdatensatz\n",
    "TrainSet = np.random.choice(inputData.shape[0],int(inputData.shape[0]*0.80), replace=False)\n",
    "ValSet = np.delete(np.arange(0, targetData.shape[0] ), TrainSet)\n",
    "XVal = inputData[ValSet,:]\n",
    "YVal = targetData[ValSet]\n",
    "XTrainSet = inputData[TrainSet,:]\n",
    "YTrainSet = targetData[TrainSet]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösungansatz I - Neural Network\n",
    "Für ein Neuronales Netzwerk gibt es unzählige Anpassungmöglichkeiten, jedoch sind durch das Ausgangsproblem ein paar Eckpunkte eine logische Konsequenz.\n",
    "- Es gibt nur **3** Möglichkeiten wie das Spielausgehen kann, daher muss auch das Netzwerk nur **3 Endergebnisse** liefern können\n",
    "- Das Spiel besitzt **6x7 Felder** mit je **3 Zuständen** -> Macht insgesamt 126 Eingabezustände. Das heißt es sollten mindestens **126 Neuronen** auf einer Netzwerkschicht sein um dies abbilden zu können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Erzeugung des Netzwerks wird als wiederverwendbare Funktion bereitgestellt\n",
    "def NetworkModel(dense_connections):\n",
    "    modelNN = tf.keras.Sequential()\n",
    "    modelNN.add(tf.keras.layers.Dense(dense_connections, activation='relu'))\n",
    "    modelNN.add(tf.keras.layers.Dense(dense_connections, activation='relu'))\n",
    "    modelNN.add(tf.keras.layers.Dense(3, activation='softplus'))\n",
    "    return modelNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Ergebnisse werden in einem Dictionary gespeichert\n",
    "results = {}\n",
    "\n",
    "# Netzwerkparameter\n",
    "epochList = [20, 30, 40]\n",
    "optimizerList = [\"adam\", \"rmsprop\", \"SGD\"]\n",
    "connectionList = [100, 200, 300]\n",
    "\n",
    "# Alle Netzwerk-Konfigurationen durchrechnen lassen\n",
    "for connections in connectionList:\n",
    "    for optimizer in optimizerList:\n",
    "        for epochs in epochList:\n",
    "            modelNN = NetworkModel(connections)\n",
    "            # Laut Doku sollte SparseCategoricalCrossentropy mit from_logits sich gut eignen für zwei oder mehr Integer Eingabeklassen\n",
    "            loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "            # gesammelt werden Daten zur Verlustfunktion und zur Genauigkeit\n",
    "            modelNN.compile(loss=loss_fn, optimizer=optimizer, metrics=['accuracy'])\n",
    "            # Das Netz wird nun anhand der Testdaten trainiert \n",
    "            history = modelNN.fit(XTrainSet, YTrainSet, epochs=epochs)\n",
    "            # Das trainierte Netz wird nun anhand der Validierungdaten überprüft\n",
    "            val_loss, val_accuracy = modelNN.evaluate(XVal, YVal, verbose=2)\n",
    "            # Alle relevanten Ergebnisse/Parameter des Netzes werden gespeichert\n",
    "            result = {\n",
    "                \"connections\": connections,\n",
    "                \"optimizer\": optimizer,\n",
    "                \"epochs\": epochs,\n",
    "                \"history\": history,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"val_loss\": val_loss\n",
    "            }\n",
    "            # Für eine leichtere Auswertung wird die accuracy als Key verwendet\n",
    "            results[val_accuracy] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die gesammelten Ergebnisse werden nun nach besten validierten Genauigkeit sortiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oderedDict = collections.OrderedDict(sorted(results.items(), reverse=True))\n",
    "\n",
    "# Top3 Netzwerke\n",
    "modellNN_1 = list(oderedDict.values())[0]\n",
    "modellNN_2 = list(oderedDict.values())[1]\n",
    "modellNN_3 = list(oderedDict.values())[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verläufe des `Lernens` der drei besten Netzwerke werden zunächst einmal visualisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(12)\n",
    "\n",
    "ax.set_title('Leistung der Top3 Netzwerke',fontsize=16)\n",
    "ax.set_xlabel('Epochs',fontsize=14)\n",
    "ax.set_ylabel('Prozent Genauigkeit',fontsize=14)\n",
    "\n",
    "ax.plot(np.arange(1, modellNN_1.get(\"epochs\")+1, 1), modellNN_1.get(\"history\").history['accuracy'], 'k--', label='Genauigkeit', color='green', marker='o' ,linewidth=2, markersize=6)\n",
    "ax.plot(np.arange(1, modellNN_1.get(\"epochs\")+1, 1), modellNN_1.get(\"history\").history['loss'], 'k:', label='Verlust', color='green', marker='o' ,linewidth=2, markersize=6)\n",
    "\n",
    "ax.plot(np.arange(1, modellNN_2.get(\"epochs\")+1, 1), modellNN_2.get(\"history\").history['accuracy'], 'k--', label='Genauigkeit', color='yellow', marker='o' ,linewidth=2, markersize=6)\n",
    "ax.plot(np.arange(1, modellNN_2.get(\"epochs\")+1, 1), modellNN_2.get(\"history\").history['loss'], 'k:', label='Verlust', color='yellow', marker='o' ,linewidth=2, markersize=6)\n",
    "\n",
    "ax.plot(np.arange(1, modellNN_3.get(\"epochs\")+1, 1), modellNN_3.get(\"history\").history['accuracy'], 'k--', label='Genauigkei', color='red', marker='o' ,linewidth=2, markersize=6)\n",
    "ax.plot(np.arange(1, modellNN_3.get(\"epochs\")+1, 1), modellNN_3.get(\"history\").history['loss'], 'k:', label='Verlust', color='red', marker='o' ,linewidth=2, markersize=6)\n",
    "\n",
    "legend = ax.legend(loc='lower left', shadow=True, fontsize='medium')\n",
    "# background color on the legend\n",
    "legend.get_frame().set_facecolor('C9')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle gesammelten Ergebnissen werden noch mal tabellarisch aufgelistet, sortiert nach dem besten Ergebnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_labels = ['Verbindungen', 'Optimizer', 'Epochen', 'Letzte trainierte Genauigkeit', 'Validierte Genauigkeit', 'Diff. Genauigkeit Training/Validierung']\n",
    "cell_data = []\n",
    "for dictionary in oderedDict.values():\n",
    "        allValues = list(dictionary.values())\n",
    "        cell_data.append([allValues[0], # Verbindungen\n",
    "                        allValues[1], # Optimizer\n",
    "                        allValues[2], # Epochen\n",
    "                        \"{:.3f}\".format(allValues[3].history.get(\"accuracy\")[-1]), # Letzte trainierte Genauigkeit, gerundet auf 3 Kommastellen\n",
    "                        \"{:.3f}\".format(allValues[4]), # Validierte Genauigkeit, gerundet auf 3 Kommastellen\n",
    "                        \"{:.3f}\".format(allValues[3].history.get(\"accuracy\")[-1] - allValues[4]) # Diff. Genauigkeit Training/Validierung, gerundet auf 3 Kommastellen\n",
    "                       ])\n",
    "\n",
    "# Using pandas du show a beautified table\n",
    "table = pd.DataFrame(cell_data, columns=column_labels)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation der I. Ergebnisse\n",
    "Es erstellte Netzwerk wurde mit einer Reihe von unterschiedlichen Konfigurationen durchlaufen. Dabei lässt sich feststellen, dass bereits nach kurzer Zeit eine richtige Vorhersagewahrscheinlichkeit des Spielausgangs von über **80%** erreicht werden kann.\n",
    "\n",
    "Für das konkrete Problem scheint der Optimizer **Adam** eine gute Wahl zu sein, da dieser sehr gehäuft auf den vorderen Plätzen vertreten ist.\n",
    "\n",
    "Bei den Verbindungen zwischen den Netzwerkschichten sind **100 zu wenig**, da diese Netzwerke weniger gute Ergebnisse lieferten.\n",
    "\n",
    "Bei der Differenz zwischen trainierter und validierter Genauigkeit fällt auf, das bereits alle Netzwerke über dem Valdierungswert trainiert wurden (positive Differenz). Das könnte auf ein sogenanntes **Overfitting** hindeuten obwohl sie laut dem Liniendiagramm wohl weiter in richtung 100% Konvergieren würden bei längerem Training. Die größte Abweichung liegt schon bei über 10%. Das ist erheblich und es scheint als wenn weniger Epochen auch weniger Differenz bedeuten. Aber hier müsste man eine genauere Experiemtierreihe starten welche nur die Trainingslängen miteinandere vergleicht. \n",
    "\n",
    "Sofern man weitere Experimente durchführen wollte, würde man diese Erkenntnisse nun nutzen können um die Variablen der Netzwerke weiter einzuschränken oder auszutauschen - z.b könnten die Optimizer `SGD` und `rmsprop` ersetzt werden `Ftrl` oder `Adamax`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösungansatz II - Neural Network - Raster\n",
    "Im zweiten Lösungsansatz wird nun versucht das Problem als Raster zu verstehen. Damit ändert sich auch die Form der Eingabevektoren für ein Neuronales Netzwerk. Es wird nun eine Matrix aufgepannt von **6 x 7 x 3** zu jedem Datensatz. Dies ergibt sich aus der Überlegung 6 x 7 Felder zu 3 Feldzuständen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Der Datensatz muss nun in eine Matrix transformiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hot encoding tranformations on Dataframe\n",
    "np_dataframe=connect4_obj.get_dataframe().to_numpy()\n",
    "only_input_entries=np_dataframe[:,:-1]\n",
    "temp=[]\n",
    "for i in range(only_input_entries.shape[0]):    \n",
    "    s = pd.Series(np_dataframe[i,:-1])\n",
    "    # die in Zahlen umgewandelten Eingaben in eine Matrix transformieren und speichern\n",
    "    temp.append(pd.get_dummies(s).to_numpy().reshape(6,7,3))    \n",
    "X = np.asarray(temp)\n",
    "print(\"Die Eingabemtrix X wurde erstellt und besitzt nun die Form: \" + str(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Ausgabevektor ist identisch mit dem ersten Lösungsansatz wird jedoch folgend mit `y` weitergeführt um die Variablen nicht mit vorherigen Ansätzen zu vermischen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shallow copy is enough due we have only a 1d-IntArray\n",
    "y = targetData.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Aufteilung von Tranings- und Validerungsdaten von Ein- und Ausgabevektoren erfolgt dieses mal mit der Hilfsfunktion `train_test_split` aus der Bibliothek `pandas`. Es übernimmt auch gleichzeitig die zufällige Auswahl an Daten sowie Größe der Aufteilung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist auch Möglich sich die Trainings- und Testdaten noch einmal zu visualiseren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(pct):\n",
    "    return \"{:.1f}%\\n[{:d}]\".format(pct, int((pct * dataframe.shape[0])/100))\n",
    "\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = 'Training', 'Test'\n",
    "sizes = [X_train.shape[0],  X_test.shape[0]]\n",
    "explode = (0, 0.06)  # only \"explode\" the 2nd slice (i.e. 'Test')\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
    "patches, texts, autotexts = ax1.pie(sizes, explode=explode, labels=labels, autopct=lambda pct: func(pct), shadow=True, startangle=90)\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    texts[i].set_fontsize(\"xx-large\")\n",
    "    autotexts[i].set_fontsize(\"xx-large\")\n",
    "    autotexts[i].set_color(\"white\")\n",
    "    autotexts[i].set_fontweight(\"bold\")\n",
    "\n",
    "\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.set_title(\"Größe des Trainings- und Test-Sets\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Struktur des Netzwerks\n",
    "Der Aufbau des Netzwerks benötigt Layer sie sich für eine Gitterstruktur eignen. Daher kommen hier beispielsweise 2D Convolutional und 2D Pooling Layer zum Einsatz welche gewöhnlich für Bildanalysen zum Einsatz kommen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network für Rastermatrix\n",
    "def Network4Raster(input_shape , dense_connections , output_shape):\n",
    "    model = tf.keras.models.Sequential([ \n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "  tf.keras.layers.Flatten(), # needed to convert the input shape for dense layers\n",
    "  tf.keras.layers.Dense(dense_connections, activation='relu'),\n",
    "  tf.keras.layers.Dense(output_shape,activation='softmax')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Darstellung eines Beispielschemas für das Netzwerk\n",
    "modelNNRaster = Network4Raster(input_shape=X.shape[1:] , dense_connections=1000 , output_shape=3)\n",
    "modelNNRaster.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Ergebnisse werden in einem Dictionary gespeichert\n",
    "resultsNNRaster = []\n",
    "\n",
    "# Netzwerkparameter\n",
    "optimizerList = [\"adam\", \"rmsprop\", \"SGD\"]\n",
    "connectionList = [500, 1000, 2000]\n",
    "epochs = 40\n",
    "\n",
    "# Alle Netzwerk-Konfigurationen durchrechnen lassen\n",
    "for connections in connectionList:\n",
    "    for optimizer in optimizerList:\n",
    "            modelNNRaster = Network4Raster(input_shape=X.shape[1:] , dense_connections=connections , output_shape=3)\n",
    "            # Laut Doku sollte SparseCategoricalCrossentropy mit from_logits sich gut eignen für zwei oder mehr Integer Eingabeklassen\n",
    "            loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "            # gesammelt werden Daten zur Verlustfunktion und zur Genauigkeit\n",
    "            modelNNRaster.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "            # Das Netz wird nun anhand der Testdaten trainiert \n",
    "            historyANNRaster = modelNNRaster.fit(X_train, y_train, epochs=epochs)\n",
    "            # Das trainierte Netz wird nun anhand der Validierungdaten überprüft\n",
    "            test_lossNNRaster, test_accuracyNNRaster = modelNNRaster.evaluate(X_test, y_test, verbose=2)\n",
    "            # Alle relevanten Ergebnisse/Parameter des Netzes werden gespeichert\n",
    "            result = {\n",
    "                \"epochs\" : epochs,\n",
    "                \"connections\": connections,\n",
    "                \"optimizer\": optimizer,\n",
    "                \"history\": historyANNRaster,\n",
    "                \"test_lossNNRaster\": test_lossNNRaster,\n",
    "                \"test_accuracyNNRaster\": test_accuracyNNRaster\n",
    "            }\n",
    "            # Alle Ergebnisse werden in einer Liste gespeichert\n",
    "            resultsNNRaster.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorierung der Ergebnisse nach der Genauigkeit\n",
    "oderedDictNNRaster = sorted(resultsNNRaster, key=lambda k: k['test_accuracyNNRaster'], reverse=True)\n",
    "\n",
    "# Top3 Netzwerke\n",
    "modellNNRaster_1 = oderedDictNNRaster[0]\n",
    "modellNNRaster_2 = oderedDictNNRaster[1]\n",
    "modellNNRaster_3 = oderedDictNNRaster[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisierung der Ergebnisse\n",
    "Die 3 besten Ergebnisse werden in einem Liniendiagramm dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(12)\n",
    "\n",
    "ax.set_title('Leistung der Top3 Netzwerke -  Raster',fontsize=16)\n",
    "ax.set_xlabel('Epochs',fontsize=14)\n",
    "ax.set_ylabel('Percentage Accuracy',fontsize=14)\n",
    "\n",
    "ax.plot(np.arange(1, modellNNRaster_1.get(\"epochs\")+1, 1), modellNNRaster_1.get(\"history\").history['accuracy'], 'k--', label='Genauigkeit', color='green', marker='o' ,linewidth=2, markersize=6)\n",
    "ax.plot(np.arange(1, modellNNRaster_1.get(\"epochs\")+1, 1), modellNNRaster_1.get(\"history\").history['loss'], 'k:', label='Verlust', color='green', marker='o' ,linewidth=2, markersize=6)\n",
    "\n",
    "ax.plot(np.arange(1, modellNNRaster_2.get(\"epochs\")+1, 1), modellNNRaster_2.get(\"history\").history['accuracy'], 'k--', label='Genauigkeit', color='yellow', marker='o' ,linewidth=2, markersize=6)\n",
    "ax.plot(np.arange(1, modellNNRaster_2.get(\"epochs\")+1, 1), modellNNRaster_2.get(\"history\").history['loss'], 'k:', label='Verlust', color='yellow', marker='o' ,linewidth=2, markersize=6)\n",
    "\n",
    "ax.plot(np.arange(1, modellNNRaster_3.get(\"epochs\")+1, 1), modellNNRaster_3.get(\"history\").history['accuracy'], 'k--', label='Genauigkeit', color='red', marker='o' ,linewidth=2, markersize=6)\n",
    "ax.plot(np.arange(1, modellNNRaster_3.get(\"epochs\")+1, 1), modellNNRaster_3.get(\"history\").history['loss'], 'k:', label='Verlust', color='red', marker='o' ,linewidth=2, markersize=6)\n",
    "\n",
    "legend = ax.legend(loc='lower left', shadow=True, fontsize='medium')\n",
    "# background color on the legend\n",
    "legend.get_frame().set_facecolor('C9')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darstellung des besten Ergebnisses als Kreisdiagramm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(pct):\n",
    "    return \"{:.1f}%\\n[{:d}]\".format(pct, int((pct * X_test.shape[0])/100))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(aspect=\"equal\"))\n",
    "\n",
    "recipe = [\"falsch klassifiziert\", \"richtig klassifiziert\"]\n",
    "\n",
    "bestAccuracy = modellNNRaster_1.get(\"test_accuracyNNRaster\")\n",
    "\n",
    "data = [(1-bestAccuracy) * X_test.shape[0] ,bestAccuracy *  X_test.shape[0]]\n",
    "explode = (0.02, 0.02) \n",
    "wedges, texts,autotexts = ax.pie(data, explode=explode, wedgeprops=dict(width=0.5), startangle=-40 \n",
    "                                 , autopct=lambda pct: func1(pct), pctdistance=0.75, labeldistance=1.0)\n",
    "autotexts[0].set_fontsize(\"large\")\n",
    "autotexts[1].set_fontsize(\"large\")\n",
    "autotexts[0].set_color(\"white\")\n",
    "autotexts[1].set_color(\"white\")\n",
    "autotexts[0].set_fontweight(\"bold\")\n",
    "autotexts[1].set_fontweight(\"bold\")\n",
    "\n",
    "bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "kw = dict(arrowprops=dict(arrowstyle=\"-\"), bbox=bbox_props, zorder=0, va=\"center\")\n",
    "\n",
    "for i, p in enumerate(wedges):\n",
    "    ang = (p.theta2 - p.theta1)/2. + p.theta1\n",
    "    y = np.sin(np.deg2rad(ang))\n",
    "    x = np.cos(np.deg2rad(ang))\n",
    "    horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "    connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n",
    "    kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n",
    "    ax.annotate(recipe[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),\n",
    "                horizontalalignment=horizontalalignment, **kw)\n",
    "\n",
    "ax.set_title(\"Prozentsatz der Fälle, die vom Netzwerk korrekt klassifiziert wurden\", fontsize=14)\n",
    "ax.legend(wedges, [\"falsch klassifiziert\" , \"richtig klassifiziert\"],\n",
    "          title=\"Gesamttestfälle : \"+str( X_test.shape[0]),\n",
    "          loc=\"center left\",\n",
    "          bbox_to_anchor=(1, 0.1, 1, 1),\n",
    "          fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabellarische Übersicht aller Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_labels = ['Epochen', 'Verbindungen', 'Optimizer', 'Letzte trainierte Genauigkeit', 'Validierte Genauigkeit', 'Diff. Genauigkeit Training/Validierung']\n",
    "cell_data = []\n",
    "for dictionary in oderedDictNNRaster:\n",
    "        allValues = list(dictionary.values())\n",
    "        cell_data.append([allValues[0], # Epochen\n",
    "                        allValues[1], # Verbindungen\n",
    "                        allValues[2], # Optimizer\n",
    "                        \"{:.3f}\".format(allValues[3].history.get(\"accuracy\")[-1]), # Letzte trainierte Genauigkeit, gerundet auf 3 Kommastellen\n",
    "                        \"{:.3f}\".format(allValues[4]), # Validierte Genauigkeit, gerundet auf 3 Kommastellen\n",
    "                        \"{:.3f}\".format(allValues[3].history.get(\"accuracy\")[-1] - allValues[4]) # Diff. Genauigkeit Training/Validierung, gerundet auf 3 Kommastellen\n",
    "                       ])\n",
    "\n",
    "# Using pandas du show a beautified table\n",
    "table = pd.DataFrame(cell_data, columns=column_labels)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation der II. Ergebnisse\n",
    "Bei dem zweiten Lösungsansatz fällt nun sofort auf, dass einige Durchläufe eine **identische Genauigkeit** liefern. Das liegt jedoch nicht daran, dass diese gleichwertig sind, sondern daran, dass diese Netzwerke überhaupt **keinen Lernfortschritt** gezeigt haben. Ihre Performance war über die gesamte Trainigsdauer konstant. Dies kann als Fehlschlag eines solchen Netzwerks bzw. ihrer Konfiguration angesehen werden.\n",
    "\n",
    "Die übrigen Netzwerke bieten eine validierte Performance von stets unter 80% mit einer relativ großen Abweichung gegenüber dem Trainingswerten.\n",
    "\n",
    "Die Parameter **Optimizern, Dense Connections**, etc. scheinen auch nur einen **sehr geringen Effekt** auf das Gesamtnetzwerk zu haben. Die tatsächlichen erzielten Ergebnisse unterscheiden um weniger als 1%. An dieser Stelle könnte ein Konstruktionsproblem der Netzwerklayer vorliegen welcher sichtbaren Fortschritt verhindert.\n",
    "\n",
    "Für weitere Experimente sollte die Gesamtkonstruktion der Layer verändert werden. Hier würde eine klare Empfehlung folgen zur Vertiefung in die Arbeit mit bildverarbeitender Layer. Die übrigen Parameter sollten dagegen in ihrer Variabilität eingeschränkt oder gänzlich auf eine feste Konfiguration festgehalten werden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösungsansatz III: DecisionTrees\n",
    "Der dritte Lösungsansatz beschäftigt sich nun mit den`Entscheidungsbäumen`. Hierfür können wir die bereits erstellten Trainings - und Validierungsdaten aus dem ersten Ansatz Wiederverwenden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufbau des DecisionTreeClassifier und Errechnung der Genauigkeit der Vorhersage\n",
    "In diesem Bereich der Implementation wird der Baum mit den Trainingsdaten aufgebaut und mit weiteren Optionen konfiguriert.\n",
    "Die hier angewendete Konfiguration \"max_leaf_nodes\" schränkt die maximale Anzahl an Blattknoten des Binärenbaumes ein. Dadurch konnte eine Genauigkeitssteigerung von bis zu 2% erreicht werden. \n",
    "Die Genauigkeit der Vorhersage ergibt sich aus dem Vergleich zwischen der Vorhersage und den Validierungsdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclf = tree.DecisionTreeClassifier(max_leaf_nodes = 2590)\n",
    "dtclf = dtclf.fit(XTrainSet, YTrainSet)\n",
    "\n",
    "# Ergebnismatrix mit nur einer Zeile\n",
    "dtclfResults = dtclf.predict(XVal)\n",
    "\n",
    "# Vergleich mit Targetwerten\n",
    "comparison = 0;\n",
    "i = 0;\n",
    "while i < dtclfResults.size:\n",
    "    if dtclfResults[i] == YVal[i]:\n",
    "        comparison += 1;\n",
    "        i+=1\n",
    "    elif dtclfResults[i] != YVal[i]:\n",
    "        i+=1\n",
    "dtclfAccuracy = (comparison/YVal.size)*100\n",
    "\n",
    "print(\"Die Vorhersagegenauigkeit des DecisionTreeClassifier beträgt: \" + str(dtclfAccuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisierung des DecisionTreeClassifier Binärbaumes\n",
    "Für die Visualisierung wird eine neuere Version der Bibliothek scikit-learn benötigt. Daher wird an dieser Stelle sichergestellt dass diese auch Verfügbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,12))  # set plot size (denoted in inches)\n",
    "tree.plot_tree(dtclf,max_depth=3, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aufbau des RandomForestClassifier und Errechnung der Genauigkeit der Vorhersage\n",
    "Der `RandomForestClassifier` Binärbaum benötigt mehr Zeit aus der DecisionTreeClassifier für den Aufbau. Dieser wird hier in der Standardkonfiguration verwendet um am konkreten Problem zu messen wie hoch die Genauigkeit solcher Bäume bereits sind ohne weitere Optimierungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(random_state=0)\n",
    "rfclf = rfclf.fit(XTrainSet, YTrainSet)\n",
    "\n",
    "# Ergebnismatrix mit nur einer Zeile\n",
    "rfclfResults = rfclf.predict(XVal)\n",
    "##Vergleich mit Targetwerten\n",
    "comparison = 0;\n",
    "i = 0;\n",
    "while i < rfclfResults.size:\n",
    "    if rfclfResults[i] == YVal[i]:\n",
    "        comparison += 1;\n",
    "        i+=1\n",
    "    elif rfclfResults[i] != YVal[i]:\n",
    "        i+=1\n",
    "rfclfAccuracy = (comparison/YVal.size)*100\n",
    "\n",
    "print(\"Die Vorhersagegenauigkeit des RandomForestClassifier beträgt: \" + str(rfclfAccuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vergleich der Lösungsansätze\n",
    "Alle 3 Lösungsansätze zeigten, dass es möglich ist mit Lernverfahren des `Maschine Learning` Vorhersagen über zukünftige Ereignisse zu treffen. Den Ausgang eines `4 Gewinnt` Spiels vorherzusagen mit einer Wahrscheinlichkeit von ~82% kann wohl als akzeptabel bezeichnet werden, welches dennoch Verbesserungspotentiale hat.\n",
    "\n",
    "Interessanterweise lieferte der erste Ansatz mit dem `Deep Neuronal Network` sowie der des `RandomForestClassifier` nahezu identische Ergebnisse. Solche Neuronalen Netze gelten in der Literatur allgemein den `DecisionTrees` als überlegen, daher liegt hier die Vermutung nahe, dass noch lange nicht das optimalste Netzwerk erstellt und trainiert wurde. Dennoch sei bemerkt dass die Erstellung und Nutzung des `RandomForestClassifier` schnell und einfach erfolgte und trotzdem ein akzeptables Ergebnis liefern konnte. Wahrscheinlich ist dies den identischen Eingabevektoren geschuldet da hier 42 lediglich 3 gleichartige Zustände existieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neue Änderungen\n",
    ".........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbeitsaufteilung\n",
    "\n",
    "\n",
    "Rituraj Singh (Mat.Nr.: 19539):\n",
    "- Erstellung, Dokumentation und Bearbeitung des RandomForestClassifier\n",
    "- Erstellung des zweiten Neuronalen Netzwerks für Rastereingaben\n",
    "- Review und Verbesserungen an Visualisierungen\n",
    "- Erstellung des ersten Neuronalen Netzwerks\n",
    "\n",
    "\n",
    "\n",
    "Kevin Bücher (Mat.Nr.: 19XXX):\n",
    "- Beschreibung des Ausgansdatensatzes\n",
    "- Review und Verbesserungen der ersten und zweiten Netzwerklösung\n",
    "- Erstellung von Visualisierungen und Ergebnisinterpretationen\n",
    "- Erstellung, Dokumentation und Bearbeitung des DecisionTreeClassifier\n",
    "- Review aller Dokumentationen und Ergebnissen\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
